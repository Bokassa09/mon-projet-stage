# Deep Learning: Module de DiffÃ©renciation Automatique en Python

## Description du Projet

Ce projet est une implÃ©mentation d'un module de diffÃ©renciation automatique en Python utilisant la surcharge d'opÃ©rateur. Le module prend en charge deux modes :

Mode Forward (propagation directe) : calcule les dÃ©rivÃ©es en suivant les opÃ©rations de maniÃ¨re sÃ©quentielle.

Mode Backward (propagation inverse) : construit un graphe computationnel pour calculer les dÃ©rivÃ©es en partant de la sortie.

La diffÃ©renciation automatique est une technique essentielle en optimisation et apprentissage automatique, offrant des dÃ©rivÃ©es exactes avec un coÃ»t calculatoire maÃ®trisÃ©. Ce module constitue une base solide pour comprendre les concepts fondamentaux des rÃ©seaux de neurones et du deep learning.

## Structure du Projet

```
stage/
â”œâ”€â”€ bobodiff/                    # ğŸ“š Module principal de diffÃ©renciation automatique
â”‚   â”œâ”€â”€ backward/               # ImplÃ©mentation du mode backward (propagation inverse)
â”‚   â”œâ”€â”€ forward/                # ImplÃ©mentation du mode forward (propagation directe)
â”‚   â””â”€â”€ utile.py               # Fonctions utilitaires communes
â”œâ”€â”€ benchmark/                  # ğŸ“Š Ã‰valuation et comparaison des performances
â”‚   â”œâ”€â”€ profile_backward.py     # Profiling du mode backward
â”‚   â”œâ”€â”€ profile_forward.py      # Profiling du mode forward
â”‚   â””â”€â”€ pytorch.py             # Comparaisons avec PyTorch
â”œâ”€â”€ exemple/                    # ğŸ§ª Exemples d'application pratique
â”‚   â”œâ”€â”€ exemple_backward.py     # Tests des fonctions du rapport (mode backward)
â”‚   â””â”€â”€ exemple_forward.py      # Tests des fonctions du rapport (mode forward)
â”œâ”€â”€ Modele/                     # ğŸ§  Applications sur rÃ©seaux de neurones
â”‚   â”œâ”€â”€ predire_note.py         # ModÃ¨le de prÃ©diction de notes
â”‚   â”œâ”€â”€ mlp_book.py            # Perceptron multicouche (thÃ©orie)
â”‚   â””â”€â”€ mlp_classe.py          # MLP de classification binaire
â”œâ”€â”€ Rapport_de_stage/           # ğŸ“„ Documentation et rapport
â”‚   â”œâ”€â”€ [Fichiers PDF]         # Fondements thÃ©oriques et mathÃ©matiques
â”‚   â””â”€â”€ soutenance.pptx        # PrÃ©sentation de soutenance
â””â”€â”€ test/                       # âœ… Suite de tests de validation
|    â”œâ”€â”€ test_backward.py        # Tests complets du mode backward
|    â””â”€â”€ test_forward.py 
|   # Tests complets du mode forward
|
â””â”€â”€ Docs/                      # ğŸ Guide d'utilisation
    â”œâ”€â”€ usage.txt               # Guide pour les deux modes 
```

### ğŸ“– Guide de navigation

**âš ï¸ Important :** Chaque rÃ©pertoire contient son propre README avec des instructions dÃ©taillÃ©es. Il est **fortement recommandÃ©** de consulter le README spÃ©cifique de chaque dossier avant d'utiliser les fichiers qu'il contient.

### RÃ©pertoires principaux

- **`bobodiff/`** : CÅ“ur du module avec les implÃ©mentations des modes forward et backward
- **`benchmark/`** : Scripts de mesure de performance et comparaisons avec des bibliothÃ¨ques Ã©tablies
- **`exemple/`** : DÃ©monstrations pratiques des fonctionnalitÃ©s sur les cas d'Ã©tude du rapport
- **`Modele/`** : Applications du module sur des architectures de rÃ©seaux de neurones
- **`test/`** : Tests exhaustifs validant toutes les opÃ©rations mathÃ©matiques implÃ©mentÃ©es
- **`Rapport_de_stage/`** : Documentation thÃ©orique complÃ¨te et prÃ©sentation finale
- **`Docs/`** : Documentation claire dâ€™utilisation de la bibliothÃ¨que bobodiff



## Objectifs

Ã‰tudier les principes de la diffÃ©renciation automatique (DA).

Concevoir une architecture modulaire en Python avec surcharge dâ€™opÃ©rateur.

ImplÃ©menter le mode Forward (propagation directe des dÃ©rivÃ©es).

ImplÃ©menter le mode Backward (propagation inverse avec graphe computationnel).

Tester sur des fonctions mathÃ©matiques et des modÃ¨les d'apprentissage.

Explorer l'utilisation de la diffÃ©renciation automatique dans les rÃ©seaux de neurones.

Comparer les performances avec des bibliothÃ¨ques comme JAX, TensorFlow et PyTorch.

## Applications en Deep Learning

Ce module peut Ãªtre utilisÃ© comme base pour comprendre et expÃ©rimenter avec les rÃ©seaux de neurones, notamment dans la mise en Å“uvre de la rÃ©tropropagation (backpropagation) utilisÃ©e dans l'apprentissage des modÃ¨les de deep learning.

## GÃ©nÃ©ration automatique de docstrings

Ce projet utilise l'extension Python Docstring Generator pour **VS Code**, permettant de gÃ©nÃ©rer automatiquement des docstrings conformes aux standards (Google, NumPy, etc.).

Cela facilite la documentation des fonctions et classes, et garantit une meilleure lisibilitÃ© et maintenabilitÃ© du code.

## PrÃ©requis

Python 3.8+

## Auteur

**BOUEKE Omer Bokassa** - Projet rÃ©alisÃ© dans le cadre d'un stage supervisÃ© par M. David DEFOUR.

**M. David DEFOUR**
Professeur d'informatique Ã  l'UniversitÃ© de Perpignan et Vice-prÃ©sident chargÃ© de la stratÃ©gie numÃ©rique et de l'intelligence artificielle.

